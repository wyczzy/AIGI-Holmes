{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28ed6952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aerdem/projects/nvidia/logits-processor-zoo\n"
     ]
    }
   ],
   "source": [
    "%cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b89279fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 04-29 15:34:27 cuda.py:22] You are using a deprecated `pynvml` package. Please install `nvidia-ml-py` instead. See https://pypi.org/project/pynvml for more information.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aerdem/projects/LLM/llmenv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 04-29 15:34:30 config.py:1563] Casting torch.bfloat16 to torch.float16.\n",
      "INFO 04-29 15:34:30 llm_engine.py:184] Initializing an LLM engine (v0.5.5) with config: model='Qwen/Qwen2.5-1.5B-Instruct', speculative_config=None, tokenizer='Qwen/Qwen2.5-1.5B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=32768, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=Qwen/Qwen2.5-1.5B-Instruct, use_v2_block_manager=False, enable_prefix_caching=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 04-29 15:34:32 model_runner.py:879] Starting to load model Qwen/Qwen2.5-1.5B-Instruct...\n",
      "INFO 04-29 15:34:32 weight_utils.py:236] Using model weights format ['*.safetensors']\n",
      "INFO 04-29 15:34:33 weight_utils.py:280] No model.safetensors.index.json found in remote.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 04-29 15:34:33 model_runner.py:890] Loading model weights took 2.8875 GB\n",
      "INFO 04-29 15:34:35 gpu_executor.py:121] # GPU blocks: 37606, # CPU blocks: 9362\n"
     ]
    }
   ],
   "source": [
    "from example_notebooks.vllm.utils import vLLMRunner\n",
    "from logits_processor_zoo.vllm import MultipleChoiceLogitsProcessor\n",
    "\n",
    "\n",
    "example_prompts = [\n",
    "\"\"\"\n",
    "I am getting a lot of calls during the day. What is more important for me to consider when I buy a new phone?\n",
    "0. Camera\n",
    "1. Screen resolution\n",
    "2. Operating System\n",
    "3. Battery\n",
    "\n",
    "\"\"\",\n",
    "    \n",
    "\"\"\"\n",
    "Which user review doesn't belong to a summer dress?\n",
    "a) Looks good\n",
    "b) Keeps warm\n",
    "c) Too long\n",
    "d) Liked the color\n",
    "\n",
    "\"\"\"\n",
    "]\n",
    "\n",
    "runner = vLLMRunner()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859aef8d",
   "metadata": {},
   "source": [
    "## Default Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbf4c2d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: \n",
      "I am getting a lot of calls during the day. What is more important for me to consider when I buy a new phone?\n",
      "0. Camera\n",
      "1. Screen resolution\n",
      "2. Operating System\n",
      "3. Battery\n",
      "\n",
      "\n",
      "When\n",
      "-----END-----\n",
      "\n",
      "Prompt: \n",
      "Which user review doesn't belong to a summer dress?\n",
      "a) Looks good\n",
      "b) Keeps warm\n",
      "c) Too long\n",
      "d) Liked the color\n",
      "\n",
      "\n",
      "The\n",
      "-----END-----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "runner.generate_response(example_prompts, max_tokens=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88bc2f8a",
   "metadata": {},
   "source": [
    "## Multiple Choice Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d74eb26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: \n",
      "I am getting a lot of calls during the day. What is more important for me to consider when I buy a new phone?\n",
      "0. Camera\n",
      "1. Screen resolution\n",
      "2. Operating System\n",
      "3. Battery\n",
      "\n",
      "\n",
      "1\n",
      "-----END-----\n",
      "\n",
      "Prompt: \n",
      "Which user review doesn't belong to a summer dress?\n",
      "a) Looks good\n",
      "b) Keeps warm\n",
      "c) Too long\n",
      "d) Liked the color\n",
      "\n",
      "\n",
      "b\n",
      "-----END-----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mclp = MultipleChoiceLogitsProcessor(runner.tokenizer, choices=[\"0\", \"1\", \"2\", \"3\"], delimiter=\".\")\n",
    "\n",
    "runner.generate_response(example_prompts[:1], [mclp], max_tokens=1)\n",
    "\n",
    "mclp = MultipleChoiceLogitsProcessor(runner.tokenizer, choices=[\"a\", \"b\", \"c\", \"d\"], delimiter=\")\")\n",
    "\n",
    "runner.generate_response(example_prompts[1:], [mclp], max_tokens=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67163806",
   "metadata": {},
   "source": [
    "## Multiple Choice Answer by boosting first words of options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88032bf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: \n",
      "I am getting a lot of calls during the day. What is more important for me to consider when I buy a new phone?\n",
      "0. Camera\n",
      "1. Screen resolution\n",
      "2. Operating System\n",
      "3. Battery\n",
      "\n",
      "\n",
      "3\n",
      "-----END-----\n",
      "\n",
      "Prompt: \n",
      "Which user review doesn't belong to a summer dress?\n",
      "a) Looks good\n",
      "b) Keeps warm\n",
      "c) Too long\n",
      "d) Liked the color\n",
      "\n",
      "\n",
      "a\n",
      "-----END-----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mclp = MultipleChoiceLogitsProcessor(runner.tokenizer, choices=[\"0\", \"1\", \"2\", \"3\"], delimiter=\".\",\n",
    "                                     boost_first_words=2.0)\n",
    "\n",
    "runner.generate_response(example_prompts[:1], [mclp], max_tokens=1)\n",
    "\n",
    "mclp = MultipleChoiceLogitsProcessor(runner.tokenizer, choices=[\"a\", \"b\", \"c\", \"d\"], delimiter=\")\", \n",
    "                                     boost_first_words=2.0)\n",
    "\n",
    "runner.generate_response(example_prompts[1:], [mclp], max_tokens=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76937c4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
