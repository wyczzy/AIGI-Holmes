# AIGC Detection with Configuration System

A comprehensive AIGC (AI-Generated Content) detection framework with unified configuration management, supporting visual pretraining and automatic model conversion to HuggingFace format.

## âœ¨ Features

- **ğŸ”§ Unified Configuration**: All parameters managed through YAML configuration files
- **ğŸš€ Complete Pipeline**: Training â†’ HuggingFace Conversion â†’ LLaVA Integration
- **ğŸ¯ Multiple Training Modes**: NPR, CLIP+LoRA, CNNDetection, and rine
- **ğŸ”„ Modular Design**: Run components independently or as complete pipeline
- **ğŸ“Š Comprehensive Testing**: Multi-dataset evaluation with detailed metrics
- **ğŸ› ï¸ Easy Setup**: Quick start script and example configurations

## ğŸš€ Quick Start

### 1. Setup
```bash
# Clone and navigate to the project
cd Baselines_AIGI

# Run quick setup
./quick_start.sh

# Edit configuration with your paths
cp config_example.yaml my_config.yaml
vim my_config.yaml
```

### 2. Run Complete Pipeline
```bash
# Full pipeline: training + conversion + integration
python train_with_config.py --config my_config.yaml
```

### 3. Run Individual Components
```bash
# Training only
python train_with_config.py --config my_config.yaml

# Model conversion only
python convert_weight2hf_config.py --config my_config.yaml

# LLaVA vision replacement only
python transform_vision_model_config.py --config my_config.yaml
```

## ğŸ“ Project Structure

```
Baselines_AIGI/
â”œâ”€â”€ ğŸ“‹ Configuration Files
â”‚   â”œâ”€â”€ config.yaml              # Main configuration template
â”‚   â”œâ”€â”€ config_example.yaml      # Detailed example configuration
â”‚   â””â”€â”€ config_loader.py         # Configuration management class
â”‚
â”œâ”€â”€ ğŸ¯ Training & Conversion Scripts  
â”‚   â”œâ”€â”€ train_with_config.py           # Unified training pipeline
â”‚   â”œâ”€â”€ convert_weight2hf_config.py    # Model â†’ HuggingFace conversion
â”‚   â””â”€â”€ transform_vision_model_config.py # LLaVA vision replacement
â”‚
â”œâ”€â”€ ğŸ“š Documentation
â”‚   â”œâ”€â”€ README.md                 # This file
â”‚   â”œâ”€â”€ README_CONFIG.md          # Detailed usage guide
â”‚   â””â”€â”€ CONFIG_SYSTEM_SUMMARY.md # Complete feature summary
â”‚
â”œâ”€â”€ ğŸ› ï¸ Setup & Dependencies
â”‚   â”œâ”€â”€ quick_start.sh           # Automated setup script
â”‚   â”œâ”€â”€ requirements_config.txt  # Python dependencies
â”‚   â””â”€â”€ requirements.txt         # Legacy requirements
â”‚
â””â”€â”€ ğŸ§  Core Components
    â”œâ”€â”€ options/                 # Training options
    â”œâ”€â”€ networks/                # Model architectures  
    â”œâ”€â”€ models/                  # Model implementations
    â”œâ”€â”€ data/                    # Data loading utilities
    â”œâ”€â”€ validate.py              # Validation functions
    â”œâ”€â”€ util.py                  # Utility functions
    â”œâ”€â”€ models.py                # Model definitions
    â””â”€â”€ test_huggingface.py      # HuggingFace testing
```

## âš™ï¸ Configuration

### Key Configuration Sections

```yaml
# Data paths
data:
  train_dataroot: "/path/to/training/data"
  test_dataroot: "/path/to/test/data"

# Model settings
training:
  trainmode: "lora"  # Options: "NPR", "lora", "CNNDetection", "rine"
  lr: 0.0001
  batch_size: 16
  niter: 1000

# Pretrained models
models:
  pretrained:
    clip_model: "/path/to/clip-vit-large-patch14-336"
    llava_model: "/path/to/llava-v1.6-mistral-7b-hf"
```

### Training Modes

| Mode | Description | Use Case |
|------|-------------|----------|
| `NPR` | Standard training | General purpose detection |
| `lora` | LoRA fine-tuning | Parameter-efficient training |
| `CNNDetection` | CNN-based detection | Traditional CNN approaches |
| `rine` | Rine method | Specialized detection method |

## ğŸ¯ Workflow

```mermaid
flowchart TD
    A[Edit Config] --> B[Run Training]
    B --> C[Model Conversion]
    C --> D[LLaVA Integration]
    D --> E[Ready for Deployment]
    
    B -.-> F[Test Model Performance]
    C -.-> G[Validate HF Model]
    D -.-> H[Test Integrated Model]
```

## ğŸ“Š Testing

The system supports comprehensive testing on multiple datasets:

- Show-o, Janus-Pro-7B, LlamaGen, Infinity
- VAR, FLUX, PixArt-XL, SD35-L
- Custom datasets via configuration

## ğŸ”§ Command Line Options

### Override Configuration
```bash
python train_with_config.py --config my_config.yaml \
    --train_dataroot /new/path \
    --batch_size 32 \
    --lr 0.0002
```

### Test Only Mode
```bash
python convert_weight2hf_config.py --config my_config.yaml --test_only
```

## ğŸ“‹ Requirements

- Python 3.8+
- PyTorch 1.11+
- Transformers 4.20+
- See `requirements_config.txt` for complete list

## ğŸ“– Documentation

- **[Detailed Usage Guide](README_CONFIG.md)**: Complete configuration and usage instructions
- **[System Summary](CONFIG_SYSTEM_SUMMARY.md)**: Comprehensive feature overview and improvements
- **[Example Config](config_example.yaml)**: Fully commented configuration example

## ğŸš¨ Common Issues

| Issue | Solution |
|-------|----------|
| Config file not found | Check file path and permissions |
| CUDA out of memory | Reduce `batch_size` in config |
| Model not found | Verify pretrained model paths |
| Permission denied | Check output directory permissions |

## ğŸ¤ Contributing

1. Follow the existing configuration patterns
2. Update documentation for new features
3. Test with multiple training modes
4. Ensure backward compatibility

## ğŸ“„ License

This project follows the original license terms. See the main repository for details.

---

**Ready to get started?** Run `./quick_start.sh` and follow the prompts! ğŸš€ 
